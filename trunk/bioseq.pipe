#!/bin/bash
#
#[version="0.3.3 ($Id$)"]
#

# Load global parameters
SP_include config.inc

###########################################################################

#[type="sysinfo"]
function bioseq_tools_version
{
	echo -n 'FastQC   : '; fastqc --version | cut -d' ' -f2
	echo -n 'bwa      : '; bwa |& grep Version | cut -d' ' -f2
	echo -n 'samtools : '; samtools |& grep Version | cut -d' ' -f2-
	echo -n 'bcftools : '; bcftools |& grep Version | cut -d' ' -f2-
	echo -n 'picard   : '; java -jar ${PICARD_ROOT}/ViewSam.jar -h |& grep Version | cut -d' ' -f2
	echo -n 'gatk     : '; java -jar ${GATK_ROOT}/GenomeAnalysisTK.jar --help | grep 'The Genome Analysis Toolkit' | cut -d',' -f1 | cut -d'v' -f2
	echo -n 'pindel   : '; pindel | grep 'Pindel version' | head -n1 | cut -d' ' -f3 | sed 's/,$//'
}

###########################################################################

function fastqc
{
	SP_set INPUT_DIR="."
	SP_set OUTPUT_DIR="."
	SP_set EXT_NAME=".fq.gz"

	#[input="${INPUT_DIR}/${NAME}${EXT_NAME}"]
	#[output.final="${OUTPUT_DIR}/${NAME}.fastqc.zip"]
	fastqc --noextract --nogroup -o ${OUTPUT_DIR}/ ${INPUT_DIR}/${NAME}${EXT_NAME} && \
		mv -vf ${OUTPUT_DIR}/$(basename ${NAME}${EXT_NAME} \
			| sed 's/\(.fastq\|\)\(.gz\|.bz2\|\)$/_fastqc.zip/g') ${OUTPUT_DIR}/${NAME}.fastqc.zip
}

function fq_33to64
{
	#Check if it is base-33
	test -n "$(${SEQPIPE_ROOT}/uxcat ${INPUT} | head -n4000 | sed -n '4~4p' | grep '[0-9]')"

	#[input="${INPUT}"]
	#[output.final="${OUTPUT}.fq.gz"]
	${SEQPIPE_ROOT}/uxcat ${INPUT} \
		| perl -e 'while($a=<>){$b=<>;$c=<>;$d=<>;print "$a$b$c"; print($_ eq "\n" ? "\n" : pack("C", unpack("C*",$_)-33+64)) for(split(//,$d));}' \
		| gzip -9c \
		> ${OUTPUT}.fq.gz
}

function fq_64to33
{
	#Check if it is base-64
	test -z "$(${SEQPIPE_ROOT}/uxcat ${INPUT} | head -n4000 | sed -n '4~4p' | grep '[0-9]')"

	#[input="${INPUT}"]
	#[output.final="${OUTPUT}.fq.gz"]
	${SEQPIPE_ROOT}/uxcat ${INPUT} \
		| perl -e 'while($a=<>){$b=<>;$c=<>;$d=<>;print "$a$b$c"; print($_ eq "\n" ? "\n" : pack("C", unpack("C*",$_)-64+33)) for(split(//,$d));}' \
		| gzip -9c \
		> ${OUTPUT}.fq.gz
}

###########################################################################

function bwa_build
{
	SP_set ALGORITHM="is"
	SP_if $(ls -lL ${FASTA} | awk '$5>=1e8')
	{
		# Treat >=100MB .fasta file as long genome, use '-a bwtsw' instead of '-a is'
		SP_set ALGORITHM="bwtsw"
	}

	#[input="${FASTA}" output.final="${FASTA}.bwt"]
	bwa index -a ${ALGORITHM} ${FASTA}
}

function bwa_map_pe
{
	SP_set INPUT_DIR="."
	SP_set OUTPUT_DIR="."

	SP_set RGID="${SAMPLE}"
	SP_set RGLB="${RGID}"
	SP_set RGPL="illumina"
	SP_set RGCN="BGI"
	SP_set OUTPUT="${SAMPLE}"

	SP_set THREAD_NUM=2
	SP_set MAX_INSERT_SIZE=500
	SP_set BWA_END_IND="5"    # do not put an indel within INT bp towards the ends.
	SP_set BWA_GAP_EXT="-1"   # maximum number of gap extensions, -1 for disabling long gaps.

	SP_set BWA_ALN_OPTS=""
	SP_set BWA_SAMPE_OPTS=""

	SP_set BWA_ALN_QUAL_OPTS=""
	SP_if (test -z "$(${SEQPIPE_ROOT}/uxcat ${INPUT_DIR}/${FQ_1} | head -n4000 | sed -n '4~4p' | grep '[0-9]')")
	{
		# Check first 1000 reads' quality, if digit characters not exist, treat it as base-64 rather than base-33.
		SP_set BWA_ALN_QUAL_OPTS="-I"
	}

	# This will be skipped if the index files exist.
	SP_run bwa_build FASTA="${REF}"

	{{
		#[require="${REF}" input="${INPUT_DIR}/${FQ_1}" output.temp="${OUTPUT_DIR}/${FQ_1}.sai"]
		bwa aln -t ${THREAD_NUM} -i ${BWA_END_IND} -e ${BWA_GAP_EXT} \
			${REF} ${INPUT_DIR}/${FQ_1} -f ${OUTPUT_DIR}/${FQ_1}.sai \
			${BWA_ALN_QUAL_OPTS} ${BWA_ALN_OPTS}
		
		#[require="${REF}" input="${INPUT_DIR}/${FQ_2}" output.temp="${OUTPUT_DIR}/${FQ_2}.sai"]
		bwa aln -t ${THREAD_NUM} -i ${BWA_END_IND} -e ${BWA_GAP_EXT} \
			${REF} ${INPUT_DIR}/${FQ_2} -f ${OUTPUT_DIR}/${FQ_2}.sai \
			${BWA_ALN_QUAL_OPTS} ${BWA_ALN_OPTS}
	}}

	#[require="${REF}"]
	#[input="${INPUT_DIR}/${FQ_1}" input="${OUTPUT_DIR}/${FQ_1}.sai"]
	#[input="${INPUT_DIR}/${FQ_2}" input="${OUTPUT_DIR}/${FQ_2}.sai"]
	#[output.final="${OUTPUT_DIR}/${OUTPUT}.bam"]
	bwa sampe -P ${REF} -a ${MAX_INSERT_SIZE} \
		${OUTPUT_DIR}/${FQ_1}.sai ${OUTPUT_DIR}/${FQ_2}.sai \
		${INPUT_DIR}/${FQ_1} ${INPUT_DIR}/${FQ_2} \
		-r "@RG\tID:${RGID}\tSM:${SAMPLE}\tLB:${RGLB}\tPL:${RGPL}\tCN:${RGCN}" \
		${BWA_SAMPE_OPTS} \
		| samtools view -Sb - \
		> ${OUTPUT_DIR}/${OUTPUT}.bam
}

function bwa_map_se
{
	SP_set INPUT_DIR="."
	SP_set OUTPUT_DIR="."

	SP_set RGID="${SAMPLE}"
	SP_set RGLB="${RGID}"
	SP_set RGPL="illumina"
	SP_set RGCN="BGI"
	SP_set OUTPUT="${SAMPLE}"

	SP_set THREAD_NUM=2
	SP_set BWA_END_IND="5"    # do not put an indel within INT bp towards the ends.
	SP_set BWA_GAP_EXT="-1"   # maximum number of gap extensions, -1 for disabling long gaps.

	SP_set BWA_ALN_OPTS=""
	SP_set BWA_SAMPE_OPTS=""

	SP_set BWA_ALN_QUAL_OPTS=""
	SP_if (test -z "$(${SEQPIPE_ROOT}/uxcat ${INPUT_DIR}/${FQ} | head -n4000 | sed -n '4~4p' | grep '[0-9]')")
	{
		# Check first 1000 reads' quality, if digit characters not exist, treat it as base-64 rather than base-33.
		SP_set BWA_ALN_QUAL_OPTS="-I"
	}

	# This will be skipped if the index files exist.
	SP_run bwa_build FASTA="${REF}"

	#[require="${REF}" input="${INPUT_DIR}/${FQ}" output.temp="${OUTPUT_DIR}/${FQ}.sai"]
	bwa aln -t ${THREAD_NUM} -i ${BWA_END_IND} -e ${BWA_GAP_EXT} \
		${REF} ${INPUT_DIR}/${FQ} -f ${OUTPUT_DIR}/${FQ}.sai \
		${BWA_ALN_QUAL_OPTS} ${BWA_ALN_OPTS}

	#[require="${REF}"]
	#[input="${INPUT_DIR}/${FQ}" input="${OUTPUT_DIR}/${FQ}.sai"]
	#[output.final="${OUTPUT_DIR}/${OUTPUT}.bam"]
	bwa samse ${REF} ${OUTPUT_DIR}/${FQ}.sai ${INPUT_DIR}/${FQ} \
		-r "@RG\tID:${RGID}\tSM:${SAMPLE}\tLB:${RGLB}\tPL:${RGPL}\tCN:${RGCN}" \
		${BWA_SAMPE_OPTS} \
		| samtools view -Sb - \
		> ${OUTPUT_DIR}/${OUTPUT}.bam
}

#[input="${INPUT_1}.bam"]
#[input="${INPUT_2}.bam"]
#[output="${OUTPUT}.bam"]
function merge_bam
{
	SP_set VALIDATION_STRINGENCY="STRICT"
	SP_set INPUT_3="${INPUT_3}"
	SP_set MORE_INPUT_FILES=""
	SP_if ${INPUT_3}
	{
		SP_set MORE_INPUT_FILES="${MORE_INPUT_FILES} INPUT=${INPUT_3}.bam"
	}

	#[input="${INPUT_1}.bam"]
	#[input="${INPUT_2}.bam"]
	#[output="${OUTPUT}.bam"]
	#[output="${OUTPUT}.bai"]
	java ${JAVA_OPTS} -jar ${PICARD_ROOT}/MergeSamFiles.jar ${PICARD_OPTS} \
		VALIDATION_STRINGENCY=${VALIDATION_STRINGENCY} \
		COMPRESSION_LEVEL=9 \
		CREATE_INDEX=true \
		CREATE_MD5_FILE=false \
		INPUT=${INPUT_1}.bam \
		INPUT=${INPUT_2}.bam \
		${MORE_INPUT_FILES} \
		OUTPUT=${OUTPUT}.bam

	#[require="${OUTPUT}.bai"]
	mv -vf ${OUTPUT}.bai ${OUTPUT}.bam.bai
}

#[input="${INPUT}.bam"]
#[output="${INPUT}.sorted.bam"]
function sort_bam
{
	SP_set VALIDATION_STRINGENCY="STRICT"

	#[input="${INPUT}.bam"]
	#[output="${INPUT}.sorted.bam"]
	#[output="${INPUT}.sorted.bai"]
	java ${JAVA_OPTS} -jar ${PICARD_ROOT}/SortSam.jar ${PICARD_OPTS} \
		VALIDATION_STRINGENCY=${VALIDATION_STRINGENCY} \
		COMPRESSION_LEVEL=9 \
		CREATE_INDEX=true \
		CREATE_MD5_FILE=false \
		SORT_ORDER=coordinate \
		INPUT=${INPUT}.bam \
		OUTPUT=${INPUT}.sorted.bam

	#[require="${INPUT}.sorted.bai"]
	mv -vf ${INPUT}.sorted.bai ${INPUT}.sorted.bam.bai
}

#[require="${REFERENCE}"]
#[input="${INPUT}.bam"]
#[output="${INPUT}.reordered.bam"]
function reorder_bam
{
	SP_set VALIDATION_STRINGENCY="STRICT"

	#[input="${INPUT}.bam"]
	#[output="${INPUT}.reordered.bam"]
	java ${JAVA_OPTS} -jar ${PICARD_ROOT}/ReorderSam.jar ${PICARD_OPTS} \
		VALIDATION_STRINGENCY=${VALIDATION_STRINGENCY} \
		COMPRESSION_LEVEL=9 \
		CREATE_INDEX=true \
		CREATE_MD5_FILE=false \
		INPUT=${INPUT}.bam \
		OUTPUT=${INPUT}.reordered.bam \
		REFERENCE=${REFERENCE}

	# Rename index file if sorted
	[ -f ${INPUT}.reordered.bai ] && mv -vf ${INPUT}.reordered.bai ${INPUT}.reordered.bam.bai
}

#[input="${INPUT}.bam"]
#[output="${INPUT}.flagstat.txt"]
function flagstat_bam
{
	#[input="${INPUT}.bam" output="${INPUT}.flagstat.txt"]
	samtools flagstat ${INPUT}.bam > ${INPUT}.flagstat.txt
}

#[input="${INPUT}.bam"]
#[output="${INPUT}.uniq.bam"]
#[output="${INPUT}.non_uniq.bam"]
function select_unique_hit_reads
{
	samtools view -h ${INPUT}.bam | tee \
		>(egrep '^@|XT:A:U' | samtools view -Sb - > ${INPUT}.uniq.bam) \
		| egrep -v 'XT:A:U' | samtools view -Sb - > ${INPUT}.non_uniq.bam
}

#[input="${INPUT}.bam"]
#[output="${INPUT}.mkdup.bam"]
function mark_duplicate_reads
{
	SP_set ASSUME_SORTED="false"
	SP_set VALIDATION_STRINGENCY="STRICT"

	#[input="${INPUT}.bam"]
	#[output="${INPUT}.mkdup.bam"]
	#[output="${INPUT}.mkdup.metrics"]
	java ${JAVA_OPTS} -jar ${PICARD_ROOT}/MarkDuplicates.jar ${PICARD_OPTS} \
		VALIDATION_STRINGENCY=${VALIDATION_STRINGENCY} \
		COMPRESSION_LEVEL=9 \
		CREATE_INDEX=true \
		CREATE_MD5_FILE=false \
		INPUT=${INPUT}.bam \
		OUTPUT=${INPUT}.mkdup.bam \
		METRICS_FILE=${INPUT}.mkdup.metrics \
		REMOVE_DUPLICATES=false

	#[require="${INPUT}.mkdup.bai"]
	mv -vf ${INPUT}.mkdup.bai ${INPUT}.mkdup.bam.bai
}

#[input="${INPUT}.bam"]
#[output="${INPUT}.rmdup.bam"]
function remove_duplicate_reads
{
	SP_set ASSUME_SORTED="false"
	SP_set VALIDATION_STRINGENCY="STRICT"

	#[input="${INPUT}.bam"]
	#[output="${INPUT}.rmdup.bam"]
	#[output="${INPUT}.rmdup.metrics"]
	java ${JAVA_OPTS} -jar ${PICARD_ROOT}/MarkDuplicates.jar ${PICARD_OPTS} \
		VALIDATION_STRINGENCY=${VALIDATION_STRINGENCY} \
		COMPRESSION_LEVEL=9 \
		CREATE_INDEX=true \
		CREATE_MD5_FILE=false \
		INPUT=${INPUT}.bam \
		OUTPUT=${INPUT}.rmdup.bam \
		METRICS_FILE=${INPUT}.rmdup.metrics \
		REMOVE_DUPLICATES=true

	#[require="${INPUT}.rmdup.bai"]
	mv -vf ${INPUT}.rmdup.bai ${INPUT}.rmdup.bam.bai
}

#[input="${INPUT}.bam"]
#[input="${INPUT}.bam.bai"]
#[output="${INPUT}.mpileup.bz2"]
function samtools_mpileup
{
	SP_set REFERENCE="${REFERENCE}"
	SP_set SAMTOOLS_OPTS=""
	SP_if ${REFERENCE}
	{
		SP_set SAMTOOLS_OPTS="${SAMTOOLS_OPTS} -f ${REFERENCE}"
	}

	samtools mpileup ${SAMTOOLS_OPTS} ${INPUT}.bam | bzip2 -9c > ${INPUT}.mpileup.bz2
}

#[require="${REFERENCE}"]
#[input="${INPUT}.bam"]
#[input="${INPUT}.bam.bai"]
#[output="${OUTPUT}.samtools.vcf"]
function samtools_call_variants
{
	samtools mpileup -f ${REFERENCE} ${INPUT}.bam -u \
		| bcftools view -vcg - \
		> ${OUTPUT}.samtools.vcf
}

#[input="${INPUT}.bam"]
#[output="${INPUT}.rg.bam"]
function picard_set_read_group
{
	# READ_GROUP_ID   : Read Group ID  Default value: 1. This option can be set to 'null' to clear the default 
	# LIBRARY         : Read Group Library  Required. 
	# PLATFORM        : Read Group platform (e.g. illumina, solid)  Required. 
	# PLATFORM_UNIT   : Read Group platform unit (eg. run barcode)  Required. 
	# SAMPLE          : Read Group sample name  Required. 
	# SEQ_CENTER_NAME : Read Group sequencing center name  Default value: null. 
	# DESCRIPTION     : Read Group description  Default value: null. 

	SP_set READ_GROUP_ID="1"
	SP_set PLATFORM="illumina"
	SP_set PLATFORM_UNIT="flowcell.lane"
	SP_set SEQ_CENTER_NAME="BGI"
	SP_set DESCRIPTION="${DESCRIPTION}"
	SP_set PICARD_RG_OPTS=""
	SP_set VALIDATION_STRINGENCY="STRICT"
	SP_if ${DESCRIPTION}
	{
		SP_set PICARD_RG_OPTS="${PICARD_RG_OPTS} RGDS=\"${DESCRIPTION}\""
	}

	#[input="${INPUT}.bam"]
	#[output="${INPUT}.rg.bam"]
	java ${JAVA_OPTS} -jar ${PICARD_ROOT}/AddOrReplaceReadGroups.jar ${PICARD_OPTS} \
		VALIDATION_STRINGENCY=${VALIDATION_STRINGENCY} \
		COMPRESSION_LEVEL=9 \
		CREATE_INDEX=true \
		CREATE_MD5_FILE=false \
		INPUT=${INPUT}.bam \
		OUTPUT=${INPUT}.rg.bam \
		RGID=${READ_GROUP_ID} \
		RGLB=${LIBRARY} \
		RGPL=${PLATFORM} \
		RGPU=${PLATFORM_UNIT} \
		RGSM=${SAMPLE} \
		RGCN=${SEQ_CENTER_NAME} \
		${PICARD_RG_OPTS}

	# Rename index file if sorted
	if [ -f ${INPUT}.rg.bai ]; then \
		mv -vf ${INPUT}.rg.bai ${INPUT}.rg.bam.bai; \
	fi
}

#[require="${REFERENCE}"]
#[require="${GATK_VCF_DBSNP}"]
#[input="${INPUT}.bam"]
#[output="${INPUT}.realign.fixmate.bam"]
function gatk_indel_realign
{
	SP_set VALIDATION_STRINGENCY="STRICT"

	#[require="${REFERENCE}"]
	#[input="${INPUT}.bam"]
	#[output="${INPUT}.intervals"]
	java ${JAVA_OPTS} -jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
		-T RealignerTargetCreator \
		-R ${REFERENCE} \
		-I ${INPUT}.bam \
		-o ${INPUT}.intervals \
		-known ${GATK_VCF_DBSNP} \
		--num_threads ${THREAD_NUM}

	#[require="${REFERENCE}"]
	#[input="${INPUT}.bam"]
	#[input="${INPUT}.intervals"]
	#[output="${INPUT}.realign.bam"]
	java ${JAVA_OPTS} -jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
		-T IndelRealigner \
		-R ${REFERENCE} \
		-I ${INPUT}.bam \
		-targetIntervals ${INPUT}.intervals \
		-o ${INPUT}.realign.bam
	
	#[input="${INPUT}.realign.bam"]
	#[output="${INPUT}.realign.fixmate.bam"]
	#[output="${INPUT}.realign.fixmate.bai"]
	java ${JAVA_OPTS} -jar ${PICARD_ROOT}/FixMateInformation.jar ${PICARD_OPTS} \
		VALIDATION_STRINGENCY=${VALIDATION_STRINGENCY} \
		COMPRESSION_LEVEL=9 \
		CREATE_INDEX=true \
		CREATE_MD5_FILE=false \
		INPUT=${INPUT}.realign.bam \
		OUTPUT=${INPUT}.realign.fixmate.bam

	#[require="${INPUT}.realign.fixmate.bai"]
	mv -vf ${INPUT}.realign.fixmate.bai ${INPUT}.realign.fixmate.bam.bai

	#[require="${INPUT}.realign.bam"]
	rm -vf ${INPUT}.intervals

	#[require="${INPUT}.realign.fixmate.bam"]
	rm -vf ${INPUT}.realign.ba{m,i}
}

#[require="${REFERENCE}"]
#[require="${GATK_VCF_DBSNP}"]
#[input="${INPUT}.bam"]
#[output="${INPUT}.recal.bam"]
function gatk_recalibrate
{
	#[require="${REFERENCE}"]
	#[require="${GATK_VCF_DBSNP}"]
	#[input="${INPUT}.bam"]
	#[output="${INPUT}.recal"]
	java ${JAVA_OPTS} \
		-jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
		-T CountCovariates \
		-R ${REFERENCE} \
		-I ${INPUT}.bam \
		-knownSites ${GATK_VCF_DBSNP} \
		-cov ReadGroupCovariate \
		-cov QualityScoreCovariate \
		-cov CycleCovariate \
		-cov DinucCovariate \
		-recalFile ${INPUT}.recal \
		--num_threads ${THREAD_NUM}
	
	#[require="${REFERENCE}"]
	#[input="${INPUT}.bam"]
	#[input="${INPUT}.recal"]
	#[output="${INPUT}.recal.bam"]
	java ${JAVA_OPTS} \
		-jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
		-T TableRecalibration \
		-R ${REFERENCE} \
		-I ${INPUT}.bam \
		-recalFile ${INPUT}.recal \
		-o ${INPUT}.recal.bam

	#[require="${INPUT}.recal.bai"]
	mv -vf ${INPUT}.recal.bai ${INPUT}.recal.bam.bai

	#[require="${INPUT}.recal.bam"]
	rm -vf ${INPUT}.recal
}

#[require="${REFERENCE}"]
#[require="${GATK_VCF_DBSNP}"]
#[input="${INPUT}.bam"]
#[output="${OUTPUT}.vcf"]
function gatk_genotype
{
	SP_set STAND_CALL_CONF=30
	SP_set STAND_EMIT_CONF=10
	SP_set MIN_BASE_QUALITY_SCORE=20

	#[require="${REFERENCE}"]
	#[require="${GATK_VCF_DBSNP}"]
	#[input="${INPUT}.bam"]
	#[output="${OUTPUT}.vcf"]
	java ${JAVA_OPTS} \
		-jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
		-T UnifiedGenotyper \
		-R ${REFERENCE} \
		-I ${INPUT}.bam \
		-glm BOTH \
		--min_base_quality_score ${MIN_BASE_QUALITY_SCORE} \
		--dbsnp ${GATK_VCF_DBSNP} \
		-stand_call_conf ${STAND_CALL_CONF} \
		-stand_emit_conf ${STAND_EMIT_CONF} \
		-o ${OUTPUT}.vcf \
		--num_threads ${THREAD_NUM}
}

#[require="${REFERENCE}"]
#[input="${INPUT}.vcf"]
#[output="${INPUT}.filtered.vcf"]
function gatk_filter_variants
{
	SP_set FILTER_NAME="Filter"
	SP_set FILTER_EXPRESSION="(AB ?: 0) > 0.75 || QUAL < 50.0 || DP < 10 || DP > 360 || (SB ?: -1) > -0.1 || MQ0 >= 4"

##### Select Different Types of Variants #####
	{{
		#[require="${REFERENCE}"]
		#[input="${INPUT}.vcf"]
		#[output="${INPUT}.snp.vcf"]
		java ${JAVA_OPTS} \
			-jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
			-T SelectVariants \
			-R ${REFERENCE} \
			--variant ${INPUT}.vcf \
			-selectType SNP -selectType MNP \
			-o ${INPUT}.snp.vcf

		#[require="${REFERENCE}"]
		#[input="${INPUT}.vcf"]
		#[output="${INPUT}.indel.vcf"]
		java ${JAVA_OPTS} \
			-jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
			-T SelectVariants \
			-R ${REFERENCE} \
			--variant ${INPUT}.vcf \
			-selectType INDEL \
			-o ${INPUT}.indel.vcf
	}}

##### Filter Variants #####
	{{
		#[require="${REFERENCE}"]
		#[input="${INPUT}.snp.vcf"]
		#[output="${INPUT}.snp.filtered.vcf"]
		java ${JAVA_OPTS} \
			-jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
			-T VariantFiltration \
			-R ${REFERENCE} \
			--variant ${INPUT}.snp.vcf \
			--filterExpression "${FILTER_EXPRESSION}" \
			--filterName "${FILTER_NAME}" \
			--clusterWindowSize 10 \
			-o ${INPUT}.snp.filtered.vcf

		#[require="${REFERENCE}"]
		#[input="${INPUT}.indel.vcf"]
		#[output="${INPUT}.indel.filtered.vcf"]
		java ${JAVA_OPTS} \
			-jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
			-T VariantFiltration \
			-R ${REFERENCE} \
			--variant ${INPUT}.snp.vcf \
			--filterExpression "${FILTER_EXPRESSION}" \
			--filterName "${FILTER_NAME}" \
			--clusterWindowSize 10 \
			-o ${INPUT}.indel.filtered.vcf
	}}

##### Combine Variants #####
	#[input="${INPUT}.snp.filtered.vcf"]
	#[input="${INPUT}.indel.filtered.vcf"]
	#[output="${INPUT}.filtered.vcf"]
	java ${JAVA_OPTS} \
		-jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
		-T CombineVariants \
		-R ${REFERENCE} \
		--variant:SNP ${INPUT}.snp.filtered.vcf \
		--variant:INDEL ${INPUT}.indel.filtered.vcf \
		-o ${INPUT}.filtered.vcf \
		-genotypeMergeOptions UNIQUIFY
}

#[require="${REFERENCE}"]
#[require="${GATK_VCF_DBSNP}"]
#[input="${INPUT}.bam"]
#[output="${OUTPUT}.gatk.vcf"]
function gatk_call_variants
{
	SP_set VALIDATION_STRINGENCY="STRICT"

	SP_run gatk_indel_realign \
		REFERENCE=${REFERENCE} GATK_VCF_DBSNP=${GATK_VCF_DBSNP} \
		INPUT=${INPUT} \
		VALIDATION_STRINGENCY=${VALIDATION_STRINGENCY}

	SP_run gatk_recalibrate \
		REFERENCE=${REFERENCE} GATK_VCF_DBSNP=${GATK_VCF_DBSNP} \
		INPUT=${INPUT}.realign.fixmate

	SP_run gatk_genotype \
		REFERENCE=${REFERENCE} GATK_VCF_DBSNP=${GATK_VCF_DBSNP} \
		INPUT=${INPUT}.realign.fixmate.recal \
		OUTPUT=${OUTPUT}

	SP_run gatk_filter_variants \
		REFERENCE=${REFERENCE} \
		INPUT=${OUTPUT}

	#[require="${OUTPUT}.filtered.vcf"]
	mv -vf ${OUTPUT}.filtered.vcf ${OUTPUT}.gatk.vcf
}

#[type="evaluator"]
function get_file_name
{
	basename ${FILE} | sed 's,\.[^.]*$,,'
}

#[type="evaluator"]
function get_file_date
{
	stat ${FILE} | grep Modify | awk '{print $2}' | sed 's,-,,g'
}

#[require="${REFERENCE}"]
#[input="${INPUT}.bam"]
#[require="${INPUT}.bam.bai"]
#[output="${OUTPUT}.pindel.vcf"]
function pindel_call_structure_variants
{
	SP_eval REFERENCE_NAME get_file_name FILE=${REFERENCE}
	SP_eval REFERENCE_DATE get_file_date FILE=${REFERENCE}

##### Call Structure Variants #####
	#[require="${REFERENCE}"]
	#[input="${INPUT}.bam"]
	#[output="${OUTPUT}_D"]
	#[output="${OUTPUT}_SI"]
	#[output="${OUTPUT}_INV"]
	#[output="${OUTPUT}_TD"]
	pindel -f ${REFERENCE} \
		-i <(echo "${INPUT}.bam ${INSERT_SIZE} ${SAMPLE}") \
		-l -k -s -c ALL -o ${OUTPUT}

##### Convert to VCF #####
	{{
		#[require="${REFERENCE}"]
		#[input="${OUTPUT}_D"]
		#[output="${OUTPUT}_D.vcf"]
		pindel2vcf -r ${REFERENCE} -R ${REFERENCE_NAME} -d ${REFERENCE_DATE} \
			-p ${OUTPUT}_D -v ${OUTPUT}_D.vcf

		#[require="${REFERENCE}"]
		#[input="${OUTPUT}_SI"]
		#[output="${OUTPUT}_SI.vcf"]
		pindel2vcf -r ${REFERENCE} -R ${REFERENCE_NAME} -d ${REFERENCE_DATE} \
			-p ${OUTPUT}_SI -v ${OUTPUT}_SI.vcf
		
		#[require="${REFERENCE}"]
		#[input="${OUTPUT}_INV"]
		#[output="${OUTPUT}_INV.vcf"]
		pindel2vcf -r ${REFERENCE} -R ${REFERENCE_NAME} -d ${REFERENCE_DATE} \
			-p ${OUTPUT}_INV -v ${OUTPUT}_INV.vcf
		
		#[require="${REFERENCE}"]
		#[input="${OUTPUT}_TD"]
		#[output="${OUTPUT}_TD.vcf"]
		pindel2vcf -r ${REFERENCE} -R ${REFERENCE_NAME} -d ${REFERENCE_DATE} \
			-p ${OUTPUT}_TD -v ${OUTPUT}_TD.vcf
	}}

##### Combine Variants #####
	#[require="${REFERENCE}"]
	#[input="${OUTPUT}_D.vcf"]
	#[input="${OUTPUT}_SI.vcf"]
	#[input="${OUTPUT}_INV.vcf"]
	#[input="${OUTPUT}_TD.vcf"]
	#[output="${INPUT}.pindel.vcf"]
	java ${JAVA_OPTS} \
		-jar ${GATK_ROOT}/GenomeAnalysisTK.jar ${GATK_OPTS} \
		-T CombineVariants \
		-R ${REFERENCE} \
		--variant:D ${OUTPUT}_D.vcf \
		--variant:SI ${OUTPUT}_SI.vcf \
		--variant:INV ${OUTPUT}_INV.vcf \
		--variant:TD ${OUTPUT}_TD.vcf \
		-o ${OUTPUT}.pindel.vcf \
		-genotypeMergeOptions UNIQUIFY
}

#[type="pipeline"]
#[require="${REFERENCE}"]
#[input="${FASTQ_1}.fq.gz"]
#[input="${FASTQ_2}.fq.gz"]
#[output="${SAMPLE}.samtools.vcf"]
#[output="${SAMPLE}.gatk.vcf"]
#[output="${SAMPLE}.pindel.vcf"]
#[output="${SAMPLE}.summary.txt"]
function DNAseq_analysis
{
	SP_set RGID="${RGID}"
	SP_set RGLB="${RGLB}"
	SP_set RGPL="${RGPL}"
	SP_set RGCN="${RGCN}"
	SP_set MAX_INSERT_SIZE=500

##### FastQC #####
	{{
		SP_run fastqc INPUT_FASTQ=${FASTQ_1}.fq.gz OUTPUT=${FASTQ_1}
		SP_run fastqc INPUT_FASTQ=${FASTQ_2}.fq.gz OUTPUT=${FASTQ_2}
	}}

##### Read Mapping #####
	SP_run bwa_map_se \
		REF=${REFERENCE} \
		FQ_1=${FASTQ_1}.fq.gz \
		FQ_2=${FASTQ_2}.fq.gz \
		MAX_INSERT_SIZE=${MAX_INSERT_SIZE} \
		OUTPUT=${SAMPLE} \
		RGID=${RGID} \
		RGLB=${RGLB} \
		SAMPLE_NAME=${SAMPLE} \
		RGPL=${RGPL} \
		RGCN=${RGCN}

##### Call Variants #####
	{{
		#[input="${SAMPLE}.bam" output="${SAMPLE}.mapped.bam"]
		samtools view ${SAMPLE}.bam -F 4 -b > ${SAMPLE}.mapped.bam
		#[input="${SAMPLE}.bam" output="${SAMPLE}.unmapped.bam"]
		samtools view ${SAMPLE}.bam -f 4 -b > ${SAMPLE}.unmapped.bam
	}}

	SP_run select_unique_hit_reads INPUT=${SAMPLE}.mapped

	SP_run sort_bam INPUT=${SAMPLE}.mapped.uniq

	SP_run mark_duplicate_reads INPUT=${SAMPLE}.mapped.uniq.sorted

	SP_run samtools_call_variants \
		REFERENCE=${REFERENCE} \
		INPUT=${SAMPLE}.mapped.uniq.sorted.mkdup \
		OUTPUT=${SAMPLE}

	SP_run gatk_call_variants \
		REFERENCE=${REFERENCE} \
		INPUT=${SAMPLE}.mapped.uniq.sorted.mkdup \
		OUTPUT=${SAMPLE}

##### Call Structure Variants #####
	SP_run sort_bam \
		VALIDATION_STRINGENCY=SILENT \
		INPUT=${SAMPLE} \
		OUTPUT=${SAMPLE}.sorted

	SP_run pindel_call_structure_variants \
		REFERENCE=${REFERENCE} \
		SAMPLE_NAME=${SAMPLE} \
		INSERT_SIZE=${INSERT_SIZE} \
		INPUT=${SAMPLE}.sorted \
		OUTPUT=${SAMPLE}

##### Report Summary Counts #####
	( \
		echo -n 'Total reads  : '; unzip -p ${FASTQ_1}.fastqc.zip '*/fastqc_data.txt' | grep 'Total Sequences' | cut -f2 | awk '{print $1+$1}'; \
		echo -n 'Mapped reads : '; samtools view -c ${SAMPLE}.mapped.bam; \
		echo -n 'Unique reads : '; samtools view -c ${SAMPLE}.mapped.uniq.bam; \
		echo -n 'Non-Duplicate: '; samtools flagstat ${SAMPLE}.mapped.uniq.sorted.mkdup.bam | head -n2 | awk '{print $1}' | paste - - | awk '{print $1-$2}'; \
		echo -n 'Variants (gatk)    :'; cat ${SAMPLE}.gatk.vcf | grep -v ^# | wc -l; \
		echo -n 'Variants (samtools):'; cat ${SAMPLE}.samtools.vcf | grep -v ^# | wc -l; \
		echo -n 'Variants (pindel)  :'; cat ${SAMPLE}.pindel.vcf | grep -v ^# | wc -l; \
	) > ${SAMPLE}.summary.txt

##### Remove Intermediate Files #####
	#[require="${SAMPLE}.mapped.uniq.bam"]
	#[require="${SAMPLE}.mapped.non_uniq.bam"]
	rm -vf ${SAMPLE}.mapped.bam
	#[require="${SAMPLE}.mapped.uniq.sorted.bam"]
	rm -vf ${SAMPLE}.mapped.uniq.bam
	#[require="${SAMPLE}.mapped.uniq.sorted.mkdup.bam"]
	rm -vf ${SAMPLE}.mapped.uniq.sorted.bam{,.bai}
}
